{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4317d6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-09-18 09:34:00,243:jax._src.xla_bridge:864: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b': Array([2., 4., 6.], dtype=float32),\n",
      " 'c': Array([1., 1., 1.], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pprint import pprint\n",
    "from tesseract_core import Tesseract\n",
    "from tesseract_jax import apply_tesseract\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "\n",
    "vectoradd = Tesseract.from_tesseract_api(\"examples/simple/partial/tesseract_api.py\")\n",
    "\n",
    "\n",
    "input_dict = {\"a\": jnp.array([1.0, 2.0, 3.0], dtype=\"float32\")}\n",
    "\n",
    "outputs = jax.jit(apply_tesseract)(vectoradd, inputs=input_dict)\n",
    "# outputs = apply_tesseract(vectoradd, inputs=input_dict)\n",
    "pprint(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1adb5855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient shape: (3,)\n"
     ]
    }
   ],
   "source": [
    "grad = vectoradd.vector_jacobian_product(\n",
    "    inputs={\n",
    "        \"a\": jnp.array([1.0, 2.0, 3.0], dtype=\"float32\"),\n",
    "    },\n",
    "    vjp_inputs=[\"a\"],\n",
    "    vjp_outputs=[\"b\"],\n",
    "    cotangent_vector={\"b\": jnp.ones((3,), dtype=\"float32\")},\n",
    ")[\"a\"]\n",
    "\n",
    "print(\"Gradient shape:\", grad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e43eeffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.extend import core\n",
    "import numpy as np\n",
    "import jax\n",
    "\n",
    "multiply_add_p = core.Primitive(\"multiply_add\")  # Create the primitive\n",
    "\n",
    "def multiply_add_prim(x, y, z):\n",
    "  \"\"\"The JAX-traceable way to use the JAX primitive.\n",
    "\n",
    "  Note that the traced arguments must be passed as positional arguments\n",
    "  to `bind`.\n",
    "  \"\"\"\n",
    "  return multiply_add_p.bind(x, y, z)\n",
    "\n",
    "def square_add_prim(a, b):\n",
    "  \"\"\"A square-add function implemented using the new JAX-primitive.\"\"\"\n",
    "  return multiply_add_prim(a, a, b)\n",
    "\n",
    "def multiply_add_impl(x, y, z):\n",
    "  \"\"\"Concrete implementation of the primitive.\n",
    "\n",
    "  This function does not need to be JAX traceable.\n",
    "\n",
    "  Args:\n",
    "    x, y, z: The concrete arguments of the primitive. Will only be called with\n",
    "      concrete values.\n",
    "\n",
    "  Returns:\n",
    "    the concrete result of the primitive.\n",
    "  \"\"\"\n",
    "  # Note: you can use the ordinary (non-JAX) NumPy, which is not JAX-traceable.\n",
    "\n",
    "  a = {\n",
    "      \"x\": x\n",
    "  }\n",
    "\n",
    "  b, treedef = jax.tree.flatten(a)\n",
    "  a = jax.tree.unflatten(treedef, b)\n",
    "\n",
    "  return np.add(np.multiply(a[\"x\"], y), z)\n",
    "\n",
    "# Now, register the primal implementation with JAX:\n",
    "multiply_add_p.def_impl(multiply_add_impl)\n",
    "\n",
    "def multiply_add_abstract_eval(xs, ys, zs):\n",
    "  \"\"\"Abstract evaluation of the primitive.\n",
    "\n",
    "  This function does not need to be JAX traceable. It will be invoked with\n",
    "  abstractions of the actual arguments\n",
    "\n",
    "  Args:\n",
    "    xs, ys, zs: Abstractions of the arguments.\n",
    "\n",
    "  Result:\n",
    "    a ShapedArray for the result of the primitive.\n",
    "  \"\"\"\n",
    "  assert xs.shape == ys.shape\n",
    "  assert xs.shape == zs.shape\n",
    "\n",
    "  raise NotImplementedError(\"Abstract eval not implemented yet\")\n",
    "  return core.ShapedArray(xs.shape, xs.dtype)\n",
    "\n",
    "# Now, register the abstract evaluation with JAX:\n",
    "multiply_add_p.def_abstract_eval(multiply_add_abstract_eval)\n",
    "\n",
    "from jax._src.lib.mlir.dialects import hlo\n",
    "def multiply_add_lowering(ctx, xc, yc, zc):\n",
    "  \"\"\"The compilation to XLA of the primitive.\n",
    "\n",
    "  Given an mlir.ir.Value for each argument, return the mlir.ir.Values for\n",
    "  the results of the function.\n",
    "\n",
    "  Does not need to be a JAX-traceable function.\n",
    "  \"\"\"\n",
    "  return [hlo.AddOp(hlo.MulOp(xc, yc), zc).result]\n",
    "\n",
    "# Now, register the lowering rule with JAX.\n",
    "# For GPU, refer to the https://docs.jax.dev/en/latest/Custom_Operation_for_GPUs.html\n",
    "from jax.interpreters import mlir\n",
    "\n",
    "mlir.register_lowering(multiply_add_p, multiply_add_lowering, platform='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ad1b098",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert square_add_prim(2., 10.) == 14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa3d0516",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Abstract eval not implemented yet",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjax\u001b[39;00m \n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mjax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjit\u001b[49m\u001b[43m(\u001b[49m\u001b[43msquare_add_prim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10.\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 13 frame]\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36msquare_add_prim\u001b[39m\u001b[34m(a, b)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msquare_add_prim\u001b[39m(a, b):\n\u001b[32m     16\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"A square-add function implemented using the new JAX-primitive.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmultiply_add_prim\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mmultiply_add_prim\u001b[39m\u001b[34m(x, y, z)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmultiply_add_prim\u001b[39m(x, y, z):\n\u001b[32m      8\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"The JAX-traceable way to use the JAX primitive.\u001b[39;00m\n\u001b[32m      9\u001b[39m \n\u001b[32m     10\u001b[39m \u001b[33;03m  Note that the traced arguments must be passed as positional arguments\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[33;03m  to `bind`.\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmultiply_add_p\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 9 frame]\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mmultiply_add_abstract_eval\u001b[39m\u001b[34m(xs, ys, zs)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m xs.shape == ys.shape\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m xs.shape == zs.shape\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAbstract eval not implemented yet\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m core.ShapedArray(xs.shape, xs.dtype)\n",
      "\u001b[31mNotImplementedError\u001b[39m: Abstract eval not implemented yet"
     ]
    }
   ],
   "source": [
    "\n",
    "import jax \n",
    "jax.jit(square_add_prim)(2., 10.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eb8921",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tessj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
