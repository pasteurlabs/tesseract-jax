{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mesh + Acoustic Optimization with PyTorch and JAX\n",
    "\n",
    "This notebook demonstrates joint optimization of:\n",
    "1. **Mesh geometry** (vertex positions)\n",
    "2. **Acoustic impedance** (boundary conditions)\n",
    "\n",
    "Using:\n",
    "- JAX-FEM for acoustic Helmholtz solver\n",
    "- PyTorch3D mesh losses for mesh regularization\n",
    "- PyTorch optimizers with JAX autodiff backend\n",
    "\n",
    "This follows the pattern from the Tesseract-JAX fem-shapeopt example, where we:\n",
    "- Wrap JAX functions to work with PyTorch\n",
    "- Use PyTorch optimizers for the optimization loop\n",
    "- Compute gradients in JAX and convert to PyTorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from jax_fem.solver import ad_wrapper, solver\n",
    "from jax_fem.generate_mesh import Mesh\n",
    "\n",
    "# Import local modules\n",
    "from problems import AcousticHelmholtzImpedance, Source\n",
    "from losses import compute_acoustic_loss\n",
    "from mesh_setup import create_square_mesh_triangular  # Square mesh with triangular elements\n",
    "\n",
    "# PyTorch for optimization and mesh losses\n",
    "import torch\n",
    "from pytorch3d.structures import Meshes\n",
    "from pytorch3d.loss import (\n",
    "    mesh_edge_loss,\n",
    "    mesh_laplacian_smoothing,\n",
    "    mesh_normal_consistency,\n",
    ")\n",
    "\n",
    "import logging\n",
    "from jax_fem import logger\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Initial Mesh and Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Physical parameters\n",
    "side_length = 2.0  # Square side length\n",
    "c = 343.0          # Speed of sound (m/s)\n",
    "f_max = 1000       # Maximum frequency (Hz)\n",
    "ppw = 5.0          # Points per wavelength\n",
    "\n",
    "# Create initial square mesh with triangular elements\n",
    "mesh, location_fns, ele_type = create_square_mesh_triangular(side_length, c, f_max, ppw)\n",
    "\n",
    "# Store initial mesh for reference\n",
    "initial_points = np.array(mesh.points)\n",
    "cells = np.array(mesh.cells)\n",
    "\n",
    "print(f\"Mesh created with {len(initial_points)} vertices and {len(cells)} cells\")\n",
    "print(f\"Element type: {ele_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize initial mesh\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.triplot(initial_points[:, 0], initial_points[:, 1], cells, 'k-', linewidth=0.5)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_title('Initial Square Mesh (Triangular Elements)')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup Acoustic Problem and Reference Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_acoustic_problem(mesh_points, cells, k, source_params, location_fns, ele_type):\n",
    "    \"\"\"Create an acoustic Helmholtz problem with given mesh.\"\"\"\n",
    "    mesh = Mesh(mesh_points, cells)\n",
    "    problem = AcousticHelmholtzImpedance(\n",
    "        mesh=mesh,\n",
    "        k=k,\n",
    "        source_params=source_params,\n",
    "        vec=1,\n",
    "        dim=2,\n",
    "        ele_type=ele_type,\n",
    "        location_fns=location_fns,\n",
    "        gauss_order=1\n",
    "    )\n",
    "    return problem\n",
    "\n",
    "# Setup acoustic parameters\n",
    "frequency = 500  # Hz\n",
    "k = 2 * jnp.pi * frequency / c\n",
    "source_params = Source(k_max=k, center=[0.0, 0.0], amplitude=1000.0)\n",
    "\n",
    "# True impedance for synthetic data\n",
    "Z_true = 1.5 + 0.3j\n",
    "\n",
    "# Create initial problem and generate reference measurements\n",
    "problem_ref = create_acoustic_problem(\n",
    "    initial_points, cells, k, source_params, location_fns, ele_type\n",
    ")\n",
    "fwd_ref = ad_wrapper(problem_ref)\n",
    "measurements = fwd_ref(Z_true)\n",
    "\n",
    "print(f\"Reference solution computed at f={frequency} Hz\")\n",
    "print(f\"True impedance: Z = {Z_true}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Loss Functions\n",
    "\n",
    "We define the acoustic loss computed in JAX using jax-fem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_acoustic_loss_jax(mesh_points, Z):\n",
    "    \"\"\"\n",
    "    Compute acoustic loss using JAX.\n",
    "    \n",
    "    Note: This function will NOT be differentiated w.r.t. mesh_points using jax.grad\n",
    "    because JAX-FEM doesn't support that. We'll use finite differences or randomized methods.\n",
    "    \"\"\"\n",
    "    # Solve acoustic problem\n",
    "    problem = create_acoustic_problem(\n",
    "        mesh_points, cells, k, source_params, location_fns, ele_type\n",
    "    )\n",
    "    fwd = ad_wrapper(problem)\n",
    "    prediction = fwd(Z)\n",
    "    \n",
    "    # Acoustic loss\n",
    "    loss_acoustic = compute_acoustic_loss(\n",
    "        problem, prediction, measurements,\n",
    "        w_mag=0.5, w_phase=0.5, w_rel=0.0\n",
    "    )\n",
    "    \n",
    "    return loss_acoustic\n",
    "\n",
    "\n",
    "def compute_mesh_gradient_randomized(mesh_points_np, Z_complex, epsilon=1e-6, n_samples=100):\n",
    "    \"\"\"\n",
    "    Compute mesh gradient using randomized directional derivatives.\n",
    "    \n",
    "    This is the practical approach when analytical adjoint isn't available.\n",
    "    Uses Johnson-Lindenstrauss random projections to estimate the gradient.\n",
    "    \n",
    "    Key insight: We don't try to use JAX's autodiff machinery at all.\n",
    "    We treat each forward solve as a black box and use numerical differentiation.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute base loss (only once!)\n",
    "    base_loss = float(compute_acoustic_loss_jax(mesh_points_np, Z_complex))\n",
    "    \n",
    "    # Use randomized directional derivatives\n",
    "    grad_estimate = np.zeros_like(mesh_points_np)\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # Random direction\n",
    "        direction = np.random.randn(*mesh_points_np.shape)\n",
    "        direction = direction / (np.linalg.norm(direction) + 1e-10)\n",
    "        \n",
    "        # Perturb in this direction\n",
    "        mesh_perturbed = mesh_points_np + epsilon * direction\n",
    "        loss_perturbed = float(compute_acoustic_loss_jax(mesh_perturbed, Z_complex))\n",
    "        \n",
    "        # Directional derivative\n",
    "        directional_deriv = (loss_perturbed - base_loss) / epsilon\n",
    "        \n",
    "        # Accumulate gradient estimate\n",
    "        grad_estimate += directional_deriv * direction\n",
    "    \n",
    "    # Average over samples\n",
    "    grad_estimate = grad_estimate / n_samples\n",
    "    \n",
    "    return grad_estimate, base_loss\n",
    "\n",
    "\n",
    "def compute_mesh_regularization_torch(mesh_points_torch):\n",
    "    \"\"\"\n",
    "    Compute PyTorch3D mesh regularization losses.\n",
    "    This returns PyTorch tensors with gradients.\n",
    "    \"\"\"\n",
    "    # Add z=0 for 2D mesh\n",
    "    z_coords = torch.zeros((mesh_points_torch.shape[0], 1), device=mesh_points_torch.device)\n",
    "    verts = torch.cat([mesh_points_torch, z_coords], dim=1).unsqueeze(0)  # (1, N, 3)\n",
    "    \n",
    "    faces = torch.from_numpy(cells).long().unsqueeze(0)  # (1, M, 3)\n",
    "    \n",
    "    # Create PyTorch3D mesh\n",
    "    mesh_pt3d = Meshes(verts=verts, faces=faces)\n",
    "    \n",
    "    # Compute losses\n",
    "    loss_edge = mesh_edge_loss(mesh_pt3d)\n",
    "    loss_laplacian = mesh_laplacian_smoothing(mesh_pt3d, method=\"uniform\")\n",
    "    loss_normal = mesh_normal_consistency(mesh_pt3d)\n",
    "    \n",
    "    # Weighted sum\n",
    "    total_loss = loss_edge + loss_laplacian + loss_normal\n",
    "    \n",
    "    return total_loss, {\n",
    "        'edge': loss_edge.item(),\n",
    "        'laplacian': loss_laplacian.item(),\n",
    "        'normal': loss_normal.item()\n",
    "    }\n",
    "\n",
    "print(\"Loss functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Combined Loss Function with JAX and PyTorch\n",
    "\n",
    "**Key limitation discovered:**\n",
    "\n",
    "Even when we try to extract the adjoint from `ad_wrapper` using `jax.vjp`, JAX still tries to trace \n",
    "through the Problem object (because the loss function references it). This triggers the same \n",
    "`jnp.take` error.\n",
    "\n",
    "**The solution:**\n",
    "\n",
    "Treat the entire forward solve as a **black box** and use **randomized finite differences**.\n",
    "This is actually the standard approach for mesh optimization in FEM:\n",
    "- Material/BC parameters → Use adjoint method (analytical derivatives available)\n",
    "- Mesh coordinates → Use finite differences (analytical shape function derivatives w.r.t. mesh are complex)\n",
    "\n",
    "We use randomized FD with ~100 samples for efficiency (~20x faster than full FD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedLoss:\n",
    "    \"\"\"Combined loss function with configurable gradient computation methods.\"\"\"\n",
    "    \n",
    "    def __init__(self, w_acoustic=1.0, w_mesh_reg=0.1, fd_epsilon=1e-6, \n",
    "                 gradient_method='random', n_samples=100):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            w_acoustic: Weight for acoustic loss\n",
    "            w_mesh_reg: Weight for mesh regularization\n",
    "            fd_epsilon: Finite difference/perturbation step size\n",
    "            gradient_method: Method for computing mesh gradients\n",
    "                - 'random': Randomized directional derivatives (recommended, ~100 solves)\n",
    "                - 'fd': Full finite differences (exact but slow, ~2N solves)\n",
    "            n_samples: Number of random samples for randomized methods\n",
    "        \"\"\"\n",
    "        self.w_acoustic = w_acoustic\n",
    "        self.w_mesh_reg = w_mesh_reg\n",
    "        self.fd_epsilon = fd_epsilon\n",
    "        self.gradient_method = gradient_method\n",
    "        self.n_samples = n_samples\n",
    "        \n",
    "        if gradient_method not in ['random', 'fd']:\n",
    "            raise ValueError(f\"gradient_method must be 'random' or 'fd', got {gradient_method}\")\n",
    "    \n",
    "    def compute_Z_gradient_fd(self, mesh_points_np, Z_complex, epsilon=1e-8):\n",
    "        \"\"\"Compute Z gradient using finite differences (fallback when JAX fails).\"\"\"\n",
    "        # Base loss\n",
    "        base_loss = float(compute_acoustic_loss_jax(mesh_points_np, Z_complex))\n",
    "        \n",
    "        # Perturb real part\n",
    "        Z_real_pert = Z_complex + epsilon\n",
    "        loss_real_pert = float(compute_acoustic_loss_jax(mesh_points_np, Z_real_pert))\n",
    "        grad_real = (loss_real_pert - base_loss) / epsilon\n",
    "        \n",
    "        # Perturb imaginary part\n",
    "        Z_imag_pert = Z_complex + 1j * epsilon\n",
    "        loss_imag_pert = float(compute_acoustic_loss_jax(mesh_points_np, Z_imag_pert))\n",
    "        grad_imag = (loss_imag_pert - base_loss) / epsilon\n",
    "        \n",
    "        return complex(grad_real, -grad_imag), base_loss\n",
    "        \n",
    "    # def compute_mesh_gradient_fd(self, mesh_points_np, Z_complex):\n",
    "    #     \"\"\"Compute acoustic loss gradient w.r.t. mesh using full finite differences.\"\"\"\n",
    "    #     n_points, n_dims = mesh_points_np.shape\n",
    "    #     grad_mesh = np.zeros_like(mesh_points_np)\n",
    "        \n",
    "    #     # Compute base loss\n",
    "    #     base_loss = float(compute_acoustic_loss_jax(mesh_points_np, Z_complex))\n",
    "        \n",
    "    #     # Compute gradient for each coordinate using finite differences\n",
    "    #     for i in range(n_points):\n",
    "    #         for d in range(n_dims):\n",
    "    #             # Perturb this coordinate\n",
    "    #             mesh_perturbed = mesh_points_np.copy()\n",
    "    #             mesh_perturbed[i, d] += self.fd_epsilon\n",
    "                \n",
    "    #             # Compute loss with perturbation\n",
    "    #             loss_perturbed = float(compute_acoustic_loss_jax(mesh_perturbed, Z_complex))\n",
    "                \n",
    "    #             # Finite difference gradient\n",
    "    #             grad_mesh[i, d] = (loss_perturbed - base_loss) / self.fd_epsilon\n",
    "        \n",
    "    #     return grad_mesh, base_loss\n",
    "    \n",
    "    def __call__(self, mesh_points_torch, Z_torch):\n",
    "        \"\"\"\n",
    "        Compute total loss and return it as PyTorch tensor.\n",
    "        \n",
    "        Args:\n",
    "            mesh_points_torch: PyTorch tensor (N, 2)\n",
    "            Z_torch: PyTorch tensor (2,) representing [real, imag]\n",
    "        \"\"\"\n",
    "        # Convert to numpy/JAX for acoustic loss\n",
    "        mesh_points_np = mesh_points_torch.detach().cpu().numpy()\n",
    "        Z_complex = complex(Z_torch[0].item(), Z_torch[1].item())\n",
    "        \n",
    "        # # Compute mesh gradients based on selected method\n",
    "        # if self.gradient_method == 'random':\n",
    "        #     # Use randomized directional derivatives (efficient)\n",
    "        #     grad_mesh_np, acoustic_loss_val = compute_mesh_gradient_randomized(\n",
    "        #         mesh_points_np, Z_complex, epsilon=self.fd_epsilon, n_samples=self.n_samples\n",
    "        #     )\n",
    "                \n",
    "        # elif self.gradient_method == 'fd':\n",
    "        #     # Use finite differences - slow but exact\n",
    "        #     grad_mesh_np, acoustic_loss_val = self.compute_mesh_gradient_fd(\n",
    "        #         mesh_points_np, Z_complex\n",
    "        #     )\n",
    "        \n",
    "        # Compute Z gradient using finite differences (safer than JAX autodiff here)\n",
    "        grad_Z_complex, loss_acoustics = self.compute_Z_gradient_fd(mesh_points_np, Z_complex)\n",
    "        \n",
    "        assert grad_Z_complex\n",
    "        \n",
    "        # Convert acoustic loss to PyTorch\n",
    "        loss_acoustics_torch = torch.tensor(\n",
    "            loss_acoustics,\n",
    "            dtype=torch.float32,\n",
    "            requires_grad=True\n",
    "        )\n",
    "        \n",
    "        # Compute mesh regularization in PyTorch (with native gradients)\n",
    "        mesh_loss, mesh_metrics = compute_mesh_regularization_torch(mesh_points_torch)\n",
    "        \n",
    "        # Combined loss\n",
    "        total_loss = self.w_acoustic * loss_acoustics_torch + self.w_mesh_reg * mesh_loss\n",
    "        \n",
    "        # Store gradients (we'll apply them manually)\n",
    "        # self.jax_grad_mesh = grad_mesh_np\n",
    "        self.jax_grad_Z = grad_Z_complex\n",
    "        \n",
    "        return total_loss, {\n",
    "            'acoustic': float(loss_acoustics),\n",
    "            'mesh': mesh_loss.item(),\n",
    "            'mesh_metrics': mesh_metrics\n",
    "        }\n",
    "\n",
    "print(\"Combined loss class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Optimization Loop with PyTorch\n",
    "\n",
    "We use PyTorch optimizers but manually apply gradients from both JAX (impedance) and finite differences (mesh)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_mesh_and_impedance(\n",
    "    initial_points, cells, measurements,\n",
    "    n_iterations=100,\n",
    "    lr_mesh=0.001,\n",
    "    lr_impedance=0.01,\n",
    "    w_acoustic=1.0,\n",
    "    w_mesh_reg=0.1,\n",
    "    gradient_method='random',\n",
    "    n_samples=100\n",
    "):\n",
    "    \"\"\"\n",
    "    Joint optimization using PyTorch optimizers with hybrid gradients.\n",
    "    \n",
    "    Args:\n",
    "        initial_points: Initial mesh vertex positions (N, 2)\n",
    "        cells: Mesh connectivity (M, 3)\n",
    "        measurements: Reference measurements for inverse problem\n",
    "        n_iterations: Number of optimization iterations\n",
    "        lr_mesh: Learning rate for mesh vertices\n",
    "        lr_impedance: Learning rate for impedance parameter\n",
    "        w_acoustic: Weight for acoustic loss\n",
    "        w_mesh_reg: Weight for mesh regularization\n",
    "        gradient_method: Method for computing mesh gradients\n",
    "            - 'random': Randomized directional derivatives (recommended, ~n_samples solves/iter)\n",
    "            - 'fd': Full finite differences (exact but slow, ~2N solves/iter)\n",
    "        n_samples: Number of random samples for randomized method\n",
    "    \"\"\"\n",
    "    # Initialize parameters as PyTorch tensors\n",
    "    mesh_points = torch.tensor(\n",
    "        initial_points, dtype=torch.float32, requires_grad=True\n",
    "    )\n",
    "    Z_params = torch.tensor(\n",
    "        [1.0, 0.1], dtype=torch.float32, requires_grad=True  # [real, imag]\n",
    "    )\n",
    "    \n",
    "    # Create optimizers\n",
    "    # optimizer_mesh = torch.optim.Adam([mesh_points], lr=lr_mesh)\n",
    "    optimizer_Z = torch.optim.Adam([Z_params], lr=lr_impedance)\n",
    "    \n",
    "    # Create loss function\n",
    "    loss_fn = CombinedLoss(\n",
    "        w_acoustic=w_acoustic, \n",
    "        w_mesh_reg=w_mesh_reg,\n",
    "        gradient_method=gradient_method,\n",
    "        n_samples=n_samples\n",
    "    )\n",
    "    \n",
    "    # History\n",
    "    history = {\n",
    "        'total_loss': [],\n",
    "        'acoustic_loss': [],\n",
    "        'mesh_loss': [],\n",
    "        'Z_history': [],\n",
    "        'mesh_history': []\n",
    "    }\n",
    "    \n",
    "    print(\"Starting optimization...\")\n",
    "    print(f\"Initial Z guess: {Z_params[0]:.4f} + {Z_params[1]:.4f}j\")\n",
    "    print(f\"True Z: {Z_true}\")\n",
    "    print(f\"Mesh gradient method: {gradient_method}\")\n",
    "    if gradient_method == 'random':\n",
    "        print(f\"  Using randomized directional derivatives (~{n_samples} solves per iteration)\")\n",
    "    elif gradient_method == 'fd':\n",
    "        print(f\"  WARNING: Using full finite differences\")\n",
    "        print(f\"  (~{2 * len(initial_points)} forward passes per iteration)\")\n",
    "    print()\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "        # Zero gradients\n",
    "        # optimizer_mesh.zero_grad()\n",
    "        optimizer_Z.zero_grad()\n",
    "        \n",
    "        # Compute loss (this computes gradients internally)\n",
    "        print(f\"Iter {i}: Computing loss and gradients...\")\n",
    "        total_loss, loss_dict = loss_fn(mesh_points, Z_params)\n",
    "        \n",
    "        # Backward pass for PyTorch components (mesh regularization)\n",
    "        total_loss.backward()        \n",
    "        \n",
    "        # Add mesh gradients from randomized FD (acoustic part)\n",
    "        # grad_mesh_torch = torch.tensor(\n",
    "        #     loss_fn.jax_grad_mesh, dtype=torch.float32\n",
    "        # )\n",
    "        # mesh_points.grad += w_acoustic * grad_mesh_torch\n",
    "        \n",
    "        # For impedance: add JAX gradients\n",
    "        grad_Z_complex_jax = loss_fn.jax_grad_Z\n",
    "        # Fix complex gradient for Wirtinger calculus\n",
    "        grad_Z_fixed = jnp.real(grad_Z_complex_jax) - 1j * jnp.imag(grad_Z_complex_jax)\n",
    "        grad_Z_torch = torch.tensor(\n",
    "            [float(jnp.real(grad_Z_fixed)), float(jnp.imag(grad_Z_fixed))],\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        if Z_params.grad is None:\n",
    "            print(\"Z_params.grad is NONE!\")\n",
    "\n",
    "        Z_params.grad = grad_Z_torch if Z_params.grad is None else Z_params.grad + w_acoustic * grad_Z_torch\n",
    "\n",
    "        if Z_params.grad is None:\n",
    "            assert False\n",
    "        \n",
    "        # NBJ clipping\n",
    "        # torch.nn.utils.clip_grad_value_(mesh_points, clip_value=0.1)\n",
    "        torch.nn.utils.clip_grad_value_(Z_params, clip_value=0.1)\n",
    "        \n",
    "        # Update parameters\n",
    "        # optimizer_mesh.step()\n",
    "        optimizer_Z.step()\n",
    "        \n",
    "        # Store history\n",
    "        Z_current = complex(Z_params[0].item(), Z_params[1].item())\n",
    "        history['total_loss'].append(total_loss.item())\n",
    "        history['acoustic_loss'].append(loss_dict['acoustic'])\n",
    "        history['mesh_loss'].append(loss_dict['mesh'])\n",
    "        history['Z_history'].append(Z_current)\n",
    "        if i % 5 == 0:  # Store mesh less frequently to save memory\n",
    "            history['mesh_history'].append(mesh_points.detach().cpu().numpy())\n",
    "        \n",
    "        # Print progress\n",
    "        print(f\"Iter {i:3d}: Loss={total_loss.item():.6f} \"\n",
    "              f\"(acoustic={loss_dict['acoustic']:.6f}, mesh={loss_dict['mesh']:.6f}) \"\n",
    "              f\"Z={Z_current:.4f}\")\n",
    "    \n",
    "    print(\"\\nOptimization complete!\")\n",
    "    print(f\"Final Z: {Z_current}\")\n",
    "    print(f\"True Z:  {Z_true}\")\n",
    "    print(f\"Error: {np.abs(Z_current - Z_true):.6f}\")\n",
    "    \n",
    "    return mesh_points.detach().cpu().numpy(), Z_current, history\n",
    "\n",
    "print(\"Optimization function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run optimization\n",
    "# \n",
    "# Gradient methods available:\n",
    "# 1. 'random' (RECOMMENDED): Randomized directional derivatives\n",
    "#                            ~100 solves per iteration (configurable with n_samples)\n",
    "#                            Based on Johnson-Lindenstrauss random projections\n",
    "#                            ~20x faster than full finite differences\n",
    "# 2. 'fd': Full finite differences (exact but very slow)\n",
    "#          ~2200 solves per iteration for this mesh\n",
    "#\n",
    "# The randomized method is the practical choice for mesh optimization in FEM!\n",
    "\n",
    "logger.setLevel(logging.NOTSET)\n",
    "\n",
    "GRADIENT_METHOD = 'random'  # Options: 'random', 'fd'\n",
    "N_SAMPLES = 50  # Number of random directions (trade-off between speed and accuracy)\n",
    "\n",
    "optimized_mesh, optimized_Z, history = optimize_mesh_and_impedance(\n",
    "    initial_points, cells, measurements,\n",
    "    n_iterations=100,\n",
    "    lr_mesh=0.01,   # Small learning rate for stability\n",
    "    lr_impedance=0.01,\n",
    "    w_acoustic=1.0,\n",
    "    w_mesh_reg=0.05,\n",
    "    gradient_method=GRADIENT_METHOD,\n",
    "    n_samples=N_SAMPLES\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Total loss\n",
    "axes[0, 0].semilogy(history['total_loss'])\n",
    "axes[0, 0].set_xlabel('Iteration')\n",
    "axes[0, 0].set_ylabel('Total Loss')\n",
    "axes[0, 0].set_title('Total Loss')\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# Acoustic vs Mesh loss\n",
    "axes[0, 1].semilogy(history['acoustic_loss'], label='Acoustic')\n",
    "axes[0, 1].semilogy(history['mesh_loss'], label='Mesh Reg')\n",
    "axes[0, 1].set_xlabel('Iteration')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].set_title('Individual Losses')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# Impedance convergence - Real part\n",
    "Z_real = [np.real(z) for z in history['Z_history']]\n",
    "axes[1, 0].plot(Z_real, label='Estimated')\n",
    "axes[1, 0].axhline(y=np.real(Z_true), color='r', linestyle='--', label='True')\n",
    "axes[1, 0].set_xlabel('Iteration')\n",
    "axes[1, 0].set_ylabel('Re(Z)')\n",
    "axes[1, 0].set_title('Impedance - Real Part')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# Impedance convergence - Imaginary part\n",
    "Z_imag = [np.imag(z) for z in history['Z_history']]\n",
    "axes[1, 1].plot(Z_imag, label='Estimated')\n",
    "axes[1, 1].axhline(y=np.imag(Z_true), color='r', linestyle='--', label='True')\n",
    "axes[1, 1].set_xlabel('Iteration')\n",
    "axes[1, 1].set_ylabel('Im(Z)')\n",
    "axes[1, 1].set_title('Impedance - Imaginary Part')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare initial vs optimized mesh\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Initial mesh\n",
    "axes[0].triplot(initial_points[:, 0], initial_points[:, 1], cells, 'b-', linewidth=0.5)\n",
    "axes[0].set_aspect('equal')\n",
    "axes[0].set_title('Initial Mesh')\n",
    "axes[0].set_xlabel('x')\n",
    "axes[0].set_ylabel('y')\n",
    "\n",
    "# Optimized mesh\n",
    "axes[1].triplot(optimized_mesh[:, 0], optimized_mesh[:, 1], cells, 'r-', linewidth=0.5)\n",
    "axes[1].set_aspect('equal')\n",
    "axes[1].set_title('Optimized Mesh')\n",
    "axes[1].set_xlabel('x')\n",
    "axes[1].set_ylabel('y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize mesh evolution\n",
    "n_snapshots = len(history['mesh_history'])\n",
    "fig, axes = plt.subplots(1, min(4, n_snapshots), figsize=(16, 4))\n",
    "\n",
    "snapshot_indices = np.linspace(0, n_snapshots-1, min(4, n_snapshots), dtype=int)\n",
    "\n",
    "for idx, snap_idx in enumerate(snapshot_indices):\n",
    "    ax = axes[idx] if n_snapshots > 1 else axes\n",
    "    mesh_snap = history['mesh_history'][snap_idx]\n",
    "    ax.triplot(mesh_snap[:, 0], mesh_snap[:, 1], cells, 'k-', linewidth=0.5)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title(f'Iteration {snap_idx * 5}')\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and visualize displacement field\n",
    "displacement = optimized_mesh - initial_points\n",
    "displacement_mag = np.linalg.norm(displacement, axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "scatter = ax.scatter(\n",
    "    initial_points[:, 0], initial_points[:, 1],\n",
    "    c=displacement_mag, cmap='viridis', s=50\n",
    ")\n",
    "ax.quiver(\n",
    "    initial_points[:, 0], initial_points[:, 1],\n",
    "    displacement[:, 0], displacement[:, 1],\n",
    "    scale=0.1, alpha=0.5\n",
    ")\n",
    "plt.colorbar(scatter, ax=ax, label='Displacement magnitude')\n",
    "ax.set_aspect('equal')\n",
    "ax.set_title('Vertex Displacement Field')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Max displacement: {displacement_mag.max():.6f}\")\n",
    "print(f\"Mean displacement: {displacement_mag.mean():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Acoustic Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve with optimized impedance parameter\n",
    "problem_opt = create_acoustic_problem(\n",
    "    final_mesh, cells, k, source_params, location_fns, ele_type\n",
    ")\n",
    "fwd_opt = ad_wrapper(problem_opt)\n",
    "solution_opt = fwd_opt(optimized_Z)\n",
    "\n",
    "# Extract pressure field\n",
    "pressure_opt = solution_opt[0][:, 0]\n",
    "pressure_ref = measurements[0][:, 0]\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Reference solution\n",
    "sc0 = axes[0].tripcolor(\n",
    "    initial_points[:, 0], initial_points[:, 1], cells,\n",
    "    np.abs(pressure_ref), shading='gouraud', cmap='viridis'\n",
    ")\n",
    "axes[0].set_aspect('equal')\n",
    "axes[0].set_title('Reference |p|')\n",
    "plt.colorbar(sc0, ax=axes[0])\n",
    "\n",
    "# Optimized solution\n",
    "sc1 = axes[1].tripcolor(\n",
    "    final_mesh[:, 0], final_mesh[:, 1], cells,\n",
    "    np.abs(pressure_opt), shading='gouraud', cmap='viridis'\n",
    ")\n",
    "axes[1].set_aspect('equal')\n",
    "axes[1].set_title('Optimized |p|')\n",
    "plt.colorbar(sc1, ax=axes[1])\n",
    "\n",
    "# Error\n",
    "error = np.abs(pressure_opt - pressure_ref)\n",
    "sc2 = axes[2].tripcolor(\n",
    "    final_mesh[:, 0], final_mesh[:, 1], cells,\n",
    "    error, shading='gouraud', cmap='hot'\n",
    ")\n",
    "axes[2].set_aspect('equal')\n",
    "axes[2].set_title('Absolute Error')\n",
    "plt.colorbar(sc2, ax=axes[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Max error: {error.max():.6e}\")\n",
    "print(f\"Mean error: {error.mean():.6e}\")\n",
    "print(f\"Relative error: {error.mean() / np.abs(pressure_ref).mean():.6%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates joint mesh and impedance optimization for acoustic inverse problems.\n",
    "\n",
    "### The Fundamental Limitation\n",
    "\n",
    "**We cannot use JAX autodiff when mesh coordinates are involved** because:\n",
    "\n",
    "1. JAX-FEM's `ad_wrapper` works great for parameters (Z, materials) when mesh is **fixed**\n",
    "2. When mesh changes, we must create a new Problem object\n",
    "3. Problem initialization uses NumPy operations that JAX can't differentiate through\n",
    "4. Even using `jax.jit` on functions that create Problems causes tracing errors\n",
    "\n",
    "**The solution**: Use finite differences for ALL gradients when doing mesh optimization.\n",
    "\n",
    "### Our Implementation\n",
    "\n",
    "**Use finite differences for both mesh and Z:**\n",
    "\n",
    "1. **For mesh coordinates**: Randomized directional derivatives\n",
    "   - Sample ~50 random directions\n",
    "   - Compute directional derivatives via FD\n",
    "   - Estimate gradient using Johnson-Lindenstrauss projections\n",
    "   - **~50 solves per iteration**\n",
    "\n",
    "2. **For impedance Z**: Also use finite differences (simpler and safer)\n",
    "   - Perturb real and imaginary parts separately\n",
    "   - **2 additional solves per iteration**\n",
    "   - Total: ~52 solves per iteration\n",
    "\n",
    "3. **For mesh regularization**: PyTorch autodiff (works perfectly!)\n",
    "   - Edge loss, Laplacian smoothing, normal consistency\n",
    "   - Native PyTorch gradients\n",
    "\n",
    "### Why This Approach Works\n",
    "\n",
    "- **Randomized FD**: Based on Johnson-Lindenstrauss lemma, provides good approximation\n",
    "- **Simple**: No complex interaction between JAX and mesh creation\n",
    "- **Robust**: Treats the FEM solver as a black box\n",
    "- **Standard practice**: This is how mesh optimization is typically done in FEM\n",
    "\n",
    "### Performance\n",
    "\n",
    "- **Random method**: ~52 solves/iteration → **practical**\n",
    "- **Full FD (if we did it for mesh)**: ~2200 solves/iteration → **impractical**  \n",
    "- **Speedup**: ~40x faster than full FD\n",
    "\n",
    "### Key Takeaway\n",
    "\n",
    "When doing mesh optimization with JAX-FEM, the cleanest approach is to:\n",
    "1. Treat the solver as a black box\n",
    "2. Use randomized finite differences for mesh gradients\n",
    "3. Use simple finite differences for other parameters (Z)\n",
    "4. Combine with PyTorch3D for mesh quality regularization\n",
    "\n",
    "This gives you a practical, working solution for joint mesh and parameter optimization!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "helmholtz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
